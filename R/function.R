#' Group a POS of proper names
#'
#' @description
#' Group a data.frame generated by spacyr::spacy_parse(), if there is a sequence of entity = PERS* / PERSON.
#' It works similar to spacyr::entity_extract(), but preserves dep_rel column
#'
#' @param DF A data.frame generated by spacyr::spacy_parse(). 
#'
#' @export
#' @examples
#' "Mary Jane loves John Smith, and Maria is loved by John Does" |>
#'   spacyr::spacy_parse(dependency = T) |>
#'   group_ppn()
#'
#' # example in Portuguese language
#' # spacy_finalize() # If spacy was previously initialized with another model.
#' spacy_initialize(model = "pt_core_news_lg")
#' "Maria Jana ama John Smith e Maria é amada por Joaquim de Souza" |>
#'   spacyr::spacy_parse(dependency = T) |>
#'   group_ppn()
group_ppn <- function(DF) {
# group_entity <- function(DF) {
  DF |>
    # dplyr::mutate(name = grepl("^PER_", entity)) |>
    dplyr::mutate(name = grepl("PROPN", pos)) |>
    dplyr::group_by(name = cumsum(0 + !(lag(name, default = TRUE) & name)), ) |>
    dplyr::mutate(name = token |>
      unique() |>
      paste(collapse = " ")) |>
    dplyr::filter(!entity == "PER_I")
}


#' Group a sequence of entities in a POS dataframe
#'
#' @description
#' Group a data.frame generated by spacyr::spacy_parse, if there is a sequence of entities
#'
#' @param DF A data.frame generated by spacyr::spacy_parse. Crated by spacy_parse()
#'
#' @export
#' @examples
#' # example in English language
#' t <- "UnitedHealthcare boss Brian Thompson, 50, was fatally shot in the back on Wednesday morning outside the Hilton hotel in Midtown Manhattan... Investigators are using surveillance photos, bullet casings with cryptic messages written on them, and the suspect's movements to track him down. They are also working with the FBI and authorities in other states as the search expands beyond New York"
#' spacyr::spacy_initialize(model = "en_core_web_lg")
#' spacyr::spacy_parse(t, dependency = T) |> group_entities()
#'
#' # example in Portuguese language
#' spacyr::spacy_initialize(model = "pt_core_news_lg")
#' "Maria Jana ama John Smith e Maria é amada por Joaquim de Souza" |>
#'   spacyr::spacy_parse(dependency = T) |>
#'   group_entities()
group_entities <- function(DF) {
# group_entity <- function(DF) {
  # DF <- spacyr::spacy_parse(t, dependency = T) 
  entities <- "^(PER(SON)?|ORG|GPE)_"

  DF |>
    dplyr::mutate(name = grepl(entities, entity)) #|>
    # dplyr::mutate(name = (entity == "(PER|PERSON|ORG)_.*")) #|>

    dplyr::group_by(name = cumsum(0 + !(dplyr::lag(name, default = TRUE) & name)), ) |>
    dplyr::mutate(name = token |>
      # unique() |>
      paste(collapse = " ")) |>
    dplyr::filter(!entity == paste0(entities, "I"))
}

#' extract entities
#' @description
#' extract entities from Spacy entities.
#' @returns a vector
#' @param DF a dataframe generated by spacyr::spacy_parse
#' @export
#' @examples
#' t |> extract_entities_v()
#'
extract_entities_v <- function(DF, rgx_entities = "^(PER(SON)?|ORG|GPE)_") {
  # entities <- "^(PER(SON)?|ORG|GPE)_"
  # entities <- rgx_entities

  DF |>
    dplyr::mutate(name = grepl(rgx_entities, entity)) |> #data.table::setDT()
    dplyr::group_by(name = cumsum(0 + !(dplyr::lag(name, default = TRUE) & name)), ) |>
    dplyr::mutate(name = token |> paste(collapse = " "))  |>
    cbind(L = DF$name) |>
    dplyr::mutate(L2 = L == T & dplyr::lag(L) == T,
      L3 = is.na(L2)) |>
    dplyr::filter(L3) |>
    # select(-L2, -L3, -L) |>
    dplyr::pull(name)

}


#' Extract entities in list format, by sentence
#' @description
#' extract entities in list, separated by sentence. 
#' @returns a vector
#' @param DF a dataframe generated by spacyr::spacy_parse
#' @export
#' @examples
#' t |> extract_entities()
#'
extract_entities_l <- function(DF, rgx_entities = "^(PER(SON)?|ORG|GPE)_") {
  doc_ids <- unique(DF$doc_id) 
  sentenc_id <- unique(DF$sentence_id)
# ID = 1
  lapply(sentenc_id, \(id_sent) {

    DF |>
      dplyr::filter(sentence_id == id_sent) |>
      extract_entities(rgx_entities)})
}

#' get entities from POS DF
#'
#' @param pos_df a pos data frame as generated by spacyr::spacy_parse() 
#' @export
#' @examples
#' pos_txt <- sample_text |> spacyr::spacy_parse()
#' pos_txt  |> get_entities(as_list = FALSE)
#' pos_txt  |> get_entities()
get_entities <- function(pos_df, as_list = TRUE,
                         rgx_entities = "^(PER(SON)?|ORG|GPE)_") {
if(as_list) {
    extract_entities_v(pos_df, rgx_entities)
  } else {
    extract_entities_l(pos_df, rgx_entities)
  }
}



# TODO collapse_sequence() # function to collapse a repeated sequence of POS

#' collapse sequence of repeated POS into a single one
#' @export
#' @examples
#' pos <- "Mary Jane was the first to drink" |> spacy_parse()
#' pos |> group_seq_pos()
#'
group_seq_pos <- function(DF, POS = "PROPN|NOUN") {
  # spacy_parse("A Folha de São Paulo apoiou a ditadura militar", dependency = T) |>
  DF |>
    dplyr::mutate(name = grepl(POS, pos)) |>
    dplyr::group_by(name = cumsum(0 + !(lag(name, default = TRUE) & name)), ) |>
    dplyr::mutate(collapsed = token |>
      unique() |>
      paste(collapse = " ")) |>
    dplyr::mutate(repet = (name == lag(name))) |>
    dplyr::filter(is.na(repet)) |>
    dplyr::select(-repet, -name)
}

#' Collapse ADP
#'
#' Collapse upos ADP, if the previous and the next pos are NOUN or PROPN. It is used in the pipeline to extract proper names like "United States of America"
#'
#' @param pos_df the POS dataframe generated by spacy_parse
#'
#' @examples
#' “The United States of America has issued a new warning to the Labor Court of the State of Mato Grosso do Sul, by way of compensation.” |>
#'  spacyr::spacy_parse(dependency = T) |>  conflate_adp()
#'
#' # in Portuguese:
#' spacy_finalize()
#' spacyr::spacy_initialize(model = "pt_core_news_lg")
#' "Os Estados Unidos da América emitiram um novo alerta para a Justiça do Trabalho do Estado do Mato Grosso do Sul, a título de indenização." |>
#'   spacyr::spacy_parse(dependency = T) |> conflate_adp()
collapse_adp <- function(pos_df) {
  pos_df |>
    # se adp é rodeado por ppn e noun = TRUE
    dplyr::mutate(
      c_adp =
        (pos == "ADP" &
          dplyr::lag(pos) %in% s2v("NOUN PROPN") &
          dplyr::lead(pos) %in% s2v("NOUN PROPN")
        ),
      token2 = ifelse(dplyr::lead(c_adp),
        paste(lemma, dplyr::lead(token), collpase = " ") |> trimws(),
        lemma
      ),
      token2 = ifelse(is.na(token2), token, token2)
    ) |>
    dplyr::rename(token0 = token, token = token2) |>
    dplyr::filter(!c_adp) |>
    dplyr::select(-c_adp)
  # select(token, pos, entity, c_adp, lemma, lemma2)
}

#' extract entities from POS
#' @return a vector of entities
extract_entities <- function(pos_df) {
  pos_df |>
    collapse_adp() |>
    # conflate_ppn()
    group_seq_pos() |>
    dplyr::filter(pos %in% s2v("NOUN PROPN")) |>
    dplyr::pull(collapsed) |> 
    trimws() |>
    unlist()
}

#' extract_entity for each sentence
#' @return a list of all entities in each sentence
extract_entities2 <- function(pos_df) {
  sentence <- unique(pos_df$sentence_id)

  lapply(sentence, \(x) {
    pos_df |>
      dplyr::filter(sentence_id == x) |>
      extract_entities()
  })
}

#' extract proper name and nouns from POS DF
#'
#' @param pos_df a data.frame generated by spacyr::spacy_parse
#' @param POS the POS to be extracted. Default: NOUN and PROPN
#' @export
#' @examples
#' pos <- "Mary Jane was the first to dance with Robert" |> spacy_parse()
#' pos |> filter_ppn()
filter_ppn <- function(pos_df, POS = c("NOUN", "PROPN")) {
  pos_df <- pos_df |>
    group_seq_pos() |>
    # dplyr::mutate(noun_ppn = grepl("NOUN|PROPN", pos )) |>
    dplyr::mutate(noun_ppn = pos %in% POS) |>
    # select(sentence_id, pos, collapsed, noun_ppn) |>
    dplyr::filter(noun_ppn) |>
    dplyr::select(-noun_ppn)

  result <- split(pos_df$collapsed, pos_df$sentence_id)
  result
}


#' extract graph of co-ocurrence from a POS dataframe
#'
#' @param pos_df a data.frame generated by spacyr::spacy_parse
#' @param POS the POS to be extracted. Defaul: NOUN and PROPN
#'
#' @export
#'
extract_graph_pos <- function(pos_df, POS = c("NOUN", "PROPN")) {
  graph <- lapply(filter_ppn(pos_df, POS = POS), \(x) {
    g_v <- combn(x, 2, simplify = F) |> unlist()

    tibble::tibble(
      n1 = g_v[seq(1, length(g_v), by = 2)],
      n2 = g_v[seq(2, length(g_v), by = 2)]
    )
  }) |>
    dplyr::bind_rows()

  if (count) {
    graph |> dplyr::count(n1, n2, sort = T)
  } else {
    graph
  }
}

#' from a vector of entities (generated by extract_entities2) returns a tibble/dataframe with co-occurence pairs
#'
#' @param entities a vector of entities generated by extract_entities2
#'
entity_list_2_graph <- function(entities) {
  comb <- entities |>
    combn(2, simplify = F) |>
    unlist()

  tibble::tibble(
    n1 = comb[seq(1, length(comb), by = 2)],
    n2 = comb[seq(2, length(comb), by = 2)]
  )
}

#' from a list of entities (generated by extract_entities2) returns a tibble/dataframe with co-occurence pairs
#'
#' @param entities_list a list object of entities generated by extract_entities2
#' @param count if TRUE returns a count of co-occurences
#'
#' @export
#'
entity_list_2_graph2 <- function(entities_list, count = TRUE) {
  # entities_list <- txt[1:3] |> paste(collapse = " ") |>
  #   spacyr::spacy_parse(dependency = T) |>
  #   extract_entities2()

  more_than1_element_in_list <- lapply(entities_list, length) |> unlist() > 1
  entities_list <- entities_list[more_than1_element_in_list]

  tib <- lapply(entities_list, entity_list_2_graph) |>
    dplyr::bind_rows()

  if (count) {
    tib |> dplyr::count(n1, n2, sort = TRUE)
  } else {
    tib
  }
}


#' Filter a graph / create an ego graph
#'
#' filter a graph / create an ego graph by term and by the number of its neighbors
#'
#' @param edges an edge dataframe
#' @param nodes a node dataframe
#' @param filter_by a term to filter the ego graph
#' @param n_neighbours the number of neighbors
#' @param as_tbl if TRUE, return a tbl_graph, if FALSE, return an igraph object
#'
#' @export
#'
#' @examples
#' # creating sample data
#' nodes <- data.frame(id = 1:5, name = LETTERS[1:5])
#' edges <- data.frame(from = c(1, 1, 2, 3, 4, 1, 6, 7), to = c(2, 3, 4, 5, 5, 4, 7, 5))
#' filter_ego(edges, nodes, filter_by = 1, n_neighbours = 1)
#' filter_ego(edges, nodes, filter_by = 1, n_neighbours = 2)
filter_ego <- function(edges, nodes = NULL, filter_by, n_neighbours = 1, as_tbl = TRUE) {
  if (is.null(nodes)) {
    message("Nodes are empty. Extracting it from edge dataframe")
    nodes <- unique(c(edges[["from"]], edges[["to"]]))
    nodes <- data.frame(id = 1:length(nodes), name = nodes)
  }

  gr <- igraph::graph_from_data_frame(edges, directed = TRUE, vertices = nodes) |>
    igraph::make_ego_graph(order = n_neighbours, nodes = filter_by, mode = c("all"))

  if (as_tbl) {
    as_tbl_graph(g[[1]])
  } else {
    gr
  }
}


#' rename cols from count
#' rename cols froum count to use with other functions, renaming to "from", "to" and "value" for n (frequency.)'
#' @export
rename_cols <- function(df) {
  df |>
    dplyr::rename(from = n1, to = n2, value = n) #|> head(100
}

#' extract nodes from a dataframe of two columns of nodes'
extract_nodes <- function(graph) {
  vert <- unique(c(graph$n1, graph$n2))

  tibble(
    id = 1:length(vert),
    label = vert
  )
}

#' split a tidy graph (each line is graph with at least 2 nodes) into two dataframes within a list: one with de nodes and its indexes, a second dataframe with de edges.
#' @export
#'
#' @examples
#' DF <- data.frame(from = c("Amanda", "Bruno", "Carlos", "Daniel"), to = c("Bruno", "Carlos", "Daniel", "Amanda"))
#'
#' split_graph(DF)
split_graph <- function(DF_graph) {
  # Create a unique list of all nodes (vertices)
  unique_nodes <- unique(c(DF_graph$from, DF_graph$to))

  # Create a mapping between node names and indices
  node_mapping <- tibble::tibble(
    id = seq_along(unique_nodes),
    label = unique_nodes
  )
  # node_mapping <- extract_nodes(DF_graph)

  # Replace node names with indices in the graph data
  graph_data <- DF_graph |>
    tibble::as_tibble() |>
    dplyr::mutate(
      from = purrr::map_chr(from, ~ node_mapping$id[node_mapping$label == .x] |> as.character()),
      to = purrr::map_chr(to, ~ node_mapping$id[node_mapping$label == .x] |> as.character()) |> as.character()
    )

  list_ <- list(node_mapping, graph_data)
  names(list_) <- c("node_index", "edges")
  list_
}



#' from semgram output, join passive and active voices
#' # VER great..../GR_analise
extract_triplets <- function(semgram) {
  At <- semgram$agent_treatments |>
    rename(from = Agent, label = treatment, to = Entity)
  aP <- semgram$action_patients |>
    rename(from = Entity, label = action, to = Patient)

  dplyr::bind_rows(At, aP) |>
    # semgramGR2$action_patients
    # triplCount <- triplets |>
    dplyr::count(from, label, to, sort = T) |>
    dplyr::rename(value = n) |>
    tibble::as_tibble() |>
    dplyr::arrange(-value)
}
