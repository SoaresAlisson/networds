# functions to build graphs using entities co-ocurrence, from 1) text; 2) word of departure.
# Given a text, the functions here filters the sentences with the query, build the graph,
# find the N neighbours to expand

#' tokenize and filter text by query
#'
#' @description
#' from vector of texts, tokenize by sentence or paragraph and returns a filtered list
#'
#' @param txt vector of texts
#' @param query query to filter the text
#' @param ic ignore case (default TRUE)
#' @param by_sentence tokenize by sentence (default TRUE). If FALSE, tokenize by paragraph
#' @param unlist if TRUE (default FALSE), returns a vector instead of a list object.
#' @export
#'
#' @examples
#' # loading data
#' data(package="txtnet")
#' # sample
#' txt_wiki[2:3]
#' txt_wiki |> filter_by_query("York")
#' txt_wiki |> filter_by_query("Police")
filter_by_query <- function(txt, query, ic = TRUE, by_sentence = TRUE, unlist = FALSE) {
  # txt <- txt_wiki #|> paste(collapse = ". ")
  # query <- "Police"
  # ic = TRUE
  # by_sentence = TRUE
  # unlist = FALSE

  # txt <- txt |> paste(collapse = ". ")

  if (by_sentence) {
    tokenized_txt <- txt |>
      tokenizers::tokenize_sentences()
  } else {
    tokenized_txt <- txt |>
      tokenizers::tokenize_paragraphs()
  }

  filtered_txt <- tokenized_txt |>
    lapply(\(x) grep(x = x, query, ignore.case = ic, value = TRUE))

  length_list <- filtered_txt |>
    lapply(length) |>
    unlist() |>
    sum()

  if (length_list == 0) {
    message('Query "', query, '" not found in given text.')
  } else {
    if (unlist) {
      unlist(filtered_txt)
    } else {
      filtered_txt
    }
  }
}

#' renumerate doc_id and sentence_id
#' @description
#' renumerate doc_id and sentence_id
#' @param pos_df a dataframe generated by spacyr::spacy_parse
renum_pos <- function(pos_df) {
  pos_df |>
  dplyr::mutate(
    sentence_id = gsub("text(.*)", "\\1", doc_id),
    doc_id = paste0("text", x))
      }

#' graph from co-ocurrence list
#'
#' @description
#' given a list of co-
#' @param coocurrence_list a dataframe generated by get_pairs()
#' @param strip_rgx regex to strip. Default: "^the_". To erase nothing, use ""
#' @param freq if TRUE (default), returns a dataframe with frequency. If FALSE, returns only the pairs
graph_from_coocurrence_list <- function(coocurrence_list, strip_rgx = "^the_", freq = TRUE) {
  comb <- coocurrence_list |>
    dplyr::pull(terms) |> 
    as.list() |> 
    lapply(combn, 2, simplify=FALSE) |>
    unlist()

    comb <- gsub(strip_rgx, "", comb)

   pairs <-  tibble::tibble(
      n1 = comb[seq(1, length(comb), by = 2)],
      n2 = comb[seq(2, length(comb), by = 2)]
    )

    if (freq) {
      pairs |>
        dplyr::count(n1, n2) |>
        dplyr::arrange(-n) |>
        dplyr::rename(freq = n)
    } else {
      pairs
    }
}


#' parse tokenized text into POS
#'
#' from a list of filtered text (from the function filter_by_query), tags the POS/ parse with spacyr.
#' It also renumber the doc_id and sentence_id
#'
#' @param txt a list of filtered text
#' @param bind if TRUE (default), returns a single dataframe. if FALSE, returns a List object
#' @param entities if TRUE (default), returns only the entities. if FALSE, returns consolidated entities
#'
#' @export
#' @examples
#' txt_wiki |> filter_by_query("Police") |> parsePOS()
#' txt_wiki |> filter_by_query("Police") |> parsePOS(only_entities = FALSE)
parsePOS <- function(txt, bind = TRUE, only_entities = TRUE) {
  pos <- lapply(1:length(txt), \(x) {
    # check if list element is empty

    if (length(txt[[x]]) == 0) {
      txt[[x]]
    } else {
      parsed <- txt[[x]] |> spacyr::spacy_parse()

      if (only_entities) {
        spacyr::entity_extract(parsed)
      } else {
          spacyr::entity_consolidate(parsed) |>
          dplyr::mutate(
            sentence_id = gsub("text(.*)", "\\1", doc_id),
            doc_id = paste0("text", x)
          )
      }
    }
  })

  if (bind) {
    non_empty <- lapply(pos, \(x) {
      length(x) > 0
    }) |>
      unlist() |>
      unname()

    pos[non_empty] |>
      dplyr::bind_rows()
  } else {
    pos
  }
}



#' get graph (co-ocurrence of entities)
#'
#' @description
#' from a POS dataframe (using filter_by_query() |> parsePOS()) get the pairs of entities
#'
#' @param pos a dataframe generated by filter_by_query() |> parsePOS()
#' @param loop if TRUE (default: FALSE), returns a loop (self reference) in the graph
#' @param freq if TRUE (default: TRUE), returns the count (frequency) of edges/co-occurences
#'
#' @export
#' @examples
#' txt_wiki |> filter_by_query("Police") |>
#'   parsePOS() |>
#'   get_pairs()
#' txt_wiki |> filter_by_query("Police") |>
#'   parsePOS() |>
#'   get_pairs(loop = TRUE)
get_pairs <- function(pos, loop = FALSE, freq = TRUE) {
# pos <- txt_wiki |> filter_by_query("Police") |> parsePOS(only_entities=FALSE) 

# to erase loops (repeated value in both nodes, or self reference) in the graph
  entities_by_txt <-
    if (loop) {
      pos |>
        dplyr::group_by(doc_id) |>
        dplyr::summarise(entities = list(entity))
    } else {
      pos |>
        dplyr::group_by(doc_id) |>
        dplyr::summarise(entities = list(unique(entity)))
    }

  # # returns a vector of pairs in sequence.
  # comb <- entities_by_txt |> 
  #   dplyr::pull(entities) |>
  #   as.list() |>
  #   lapply(combn, 2, simplify = FALSE) |>
  #   unlist()
  #
  # # tibble from odds and evens
  # pairs <- tibble::tibble(
  #   n1 = comb[seq(1, length(comb), by = 2)],
  #   n2 = comb[seq(2, length(comb), by = 2)]
  # )
  pairs <- graph_from_coocurrence_list(entities_by_txt, freq=freq)

  # if (count) {
  #   pairs |>
  #     dplyr::count(n1, n2) |>
  #     dplyr::arrange(-n)
  # } else {
  #   pairs
  # }
}

#' get graph (co-ocurrence of entities and Nouns)
#'
#' @description
#' from a POS dataframe (using filter_by_query() |> parsePOS()) get the pairs of entities
#'
#' @param pos_df a POS dataframe
#' @param pos_cat the POS categories to be extracted. Default: NOUN and ENTITY
#'
#' @export
#' @examples
#' txt_wiki |> filter_by_query("Police") |>
#'   parsePOS(only_entities=FALSE) |>
#'   get_pairs2()
get_pairs2 <- function(pos_df, 
                       pos_cat =  c("NOUN", "ENTITY")) {

  pos2 <- pos_df |>
    dplyr::filter(pos %in% pos_cat) |> 
    dplyr::group_by(doc_id, sentence_id) |> 
    dplyr::summarise(terms = list(token)) 
 
   graph_from_coocurrence_list(pos2)
} 


#' graph from text and query
#'
#' from text and a query, generates the graph dataframe of co-ocurrence frequency
#' 
#' @param text a vector of texts
#' @param query query to filter the text
#' @param ic ignore case (default TRUE)
#' @param by_sentence tokenize by sentence (default TRUE). If FALSE, tokenize by paragraph
#' @param loop if TRUE (default: FALSE), returns a loop (self reference) in the graph
#'
#' @export
#' @examples
#' # loading data
#' data(package="txtnet")
#' # sample
#' txt_wiki[2:3]
#' txt_wiki |> get_graph_from_txt("York")
#' txt_wiki |> get_graph_from_txt("Police")
get_graph_from_txt <- function(text, query, ic = TRUE, by_sentence = TRUE, loop = FALSE) {
  text |>
    filter_by_query(query = query, ic = ic, by_sentence = by_sentence) |>
    parsePOS() |>
    get_pairs(loop = loop)
}
