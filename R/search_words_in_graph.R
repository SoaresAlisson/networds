# functions to build graphs using entities co-ocurrence, from 1) text; 2) word of departure.
# Given a text, the functions here filters the sentences with the query, build the graph,
# find the N neighbours to expand



#' tokenize and filter text by query
#'
#' @description
#' from vector of texts, tokenize by sentence or paragraph and returns a filtered list
#'
#' @param txt vector of texts
#' @param query query to filter the text
#' @param ic ignore case (default TRUE)
#' @param by_sentence tokenize by sentence (default TRUE). If FALSE, tokenize by paragraph
#' @param unlist if TRUE (default FALSE), returns a vector instead of a list object.
#' @export
#'
#' @examples
#' # loading data
#' data(package="txtnet")
#' # sample
#' txt_wiki[2:3]
#' txt_wiki |> filter_by_query("York")
#' txt_wiki |> filter_by_query("Police")
filter_by_query <- function(txt, query, i_c = TRUE, by_sentence = TRUE, unlist = FALSE) {
  # txt <- txt_wiki #|> paste(collapse = ". ")
  # query <- "Police"
  # i_c = TRUE
  # by_sentence = TRUE
  # unlist = FALSE

  # txt <- txt |> paste(collapse = ". ")

  if (by_sentence) {
    tokenized_txt <- txt |>
      tokenizers::tokenize_sentences()
  } else {
    tokenized_txt <- txt |>
      tokenizers::tokenize_paragraphs()
  }

  filtered_txt <- tokenized_txt |>
    lapply(\(x) grep(x = x, query, ignore.case = i_c, value = TRUE))

  length_list <- filtered_txt |>
    lapply(length) |>
    unlist() |>
    sum()

  if (length_list == 0) {
    message('Query "', query, '" not found in given text.')
  } else {
    if (unlist) {
      unlist(filtered_txt)
    } else {
      filtered_txt
    }
  }
}


#' parse tokenized text into POS
#'
#' from a list of filtered text (from the function filter_by_query), tags the POS/ parse with spacyr.
#' It also renumber the doc_id and sentence_id. It runs spacyr::entity_extract() or spacyr::entity_consolidate() in background,
#' but also runs os lists with empty elements,  and can returns a single dataframe (if `bind = TRUE`) renaming doc_id and sentence_id,
#'
#' @param txt a list of filtered text
#' @param bind if TRUE (default), returns a single dataframe. if FALSE, returns a List object
#' @param entities if TRUE (default), returns only the entities. if FALSE, returns consolidated entities
#'
#' @export
#' @examples
#' txt_wiki |> filter_by_query("Police") |> parsePOS()
#' txt_wiki |> filter_by_query("Police") |> parsePOS(only_entities = FALSE)
parsePOS <- function(txt, bind = TRUE, only_entities = TRUE) {
  pos <- lapply(1:length(txt), \(x) {
    # check if list element is empty

    if (length(txt[[x]]) == 0) {
      txt[[x]]
    } else {
      parsed <- txt[[x]] |> spacyr::spacy_parse()

      if (only_entities) {
        spacyr::entity_extract(parsed)
      } else {
          spacyr::entity_consolidate(parsed) |>
          dplyr::mutate(
            sentence_id = gsub("text(.*)", "\\1", doc_id),
            doc_id = paste0("text", x)
          )
      }
    }
  })

  if (bind) {
    non_empty <- lapply(pos, \(x) {
      length(x) > 0
    }) |>
      unlist() |>
      unname()

    pos[non_empty] |>
      dplyr::bind_rows()
  } else {
    pos
  }
}


#' graph from co-ocurrence list
#'
#' @description
#' given a listed dataframe of co-ocurrence, returns a dataframe with frequency. 
#' If list element has only one element, it is removed.
#'
#' @param coocurrence_list a dataframe generated by get_pairs()
#' @param strip_rgx regex to strip. Default: "^the_". To erase nothing, use "".
#' @param freq if TRUE (default), returns a dataframe with frequency. If FALSE, returns only the pairs
#'
#' @examples
#' pos <- txt_wiki |> filter_by_query("Police") |> parsePOS() 
#' entities_by_txt <- pos |> dplyr::group_by(doc_id) |> dplyr::summarise(entities = list(unique(entity))) 
#' graph_from_coocurrence_list(entities_by_txt)
graph_from_coocurrence_list <- function(coocurrence_list, strip_rgx = "^the_", freq = TRUE) {
  # coocurrence_list  <- entities_by_txt
  
  # check colnames
    column_names <- colnames( coocurrence_list )
    adequated_colnames <- !column_names %in% c("terms") |> any()

  if( adequated_colnames ) {
    coocurrence_list <- 
      coocurrence_list |>
      dplyr::rename(terms = entities)
  }

  node_list <- coocurrence_list |>
    dplyr::pull(terms) |> 
    as.list() 

  # solitary nodes without edges: catching them
    lonely_nodes <- node_list |> lapply(length) |> unlist() == 1
    lonely_nodes <- node_list[lonely_nodes] |> unlist() 
  
  # removing list elements that has length < 1
    list_length_correct <- node_list |> lapply(length) |> unlist() > 1
   
  # combinating pairs
  comb_list <- node_list[list_length_correct] |> 
    lapply(combn, 2, simplify=FALSE) |>
    unlist()

  if(strip_rgx != ""){ comb <- gsub(strip_rgx, "", comb_list) }

   pairs <-  tibble::tibble(
      n1 = comb[seq(1, length(comb), by = 2)],
      n2 = comb[seq(2, length(comb), by = 2)]
    )

    # all nodes
    all_nodes <- node_list |> unlist()

  # frequency
    if (freq) {
      edgesDF <- pairs |>
        dplyr::count(n1, n2) |>
        dplyr::arrange(-n) |>
        dplyr::rename(freq = n)

      isolated_nodes <- 
        lonely_nodes |> 
          plyr::count() |> 
          dplyr::arrange(-freq) |>  dplyr::rename(node=1)
      # colnames(isolated_nodes)  <- c("node", "freq")

      all_nodes <- 
        all_nodes  |> 
          plyr::count() |> 
          dplyr::arrange(-freq) |> 
          dplyr::rename(node=x)

    } else{
      all_nodes <- all_nodes |> unique()
    }

  list(edges = edgesDF, 
    isolated_nodes = isolated_nodes,
    nodes = all_nodes)
}


#' get graph (co-ocurrence of entities)
#'
#' @description
#' from a POS dataframe (using filter_by_query() |> parsePOS()) get the pairs of entities
#'
#' @param pos a dataframe generated by filter_by_query() |> parsePOS()
#' @param loop if TRUE (default: FALSE), returns a loop (self reference) in the graph
#' @param freq if TRUE (default: TRUE), returns the count (frequency) of edges/co-occurences
#'
#' @export
#' @examples
#' x <- txt_wiki |> filter_by_query("Police") 
#' x <- x |> parsePOS()
#' get_cooc_entities(x)
#' # with loops /self-reference
#' get_cooc_entities(x, loop = TRUE)
get_cooc_entities <- function(pos, loop = FALSE, freq = TRUE) {
# pos <- txt_wiki |> filter_by_query("Police") |> parsePOS() 

# to erase loops (repeated value in both nodes, or self reference) in the graph
  entities_by_txt <-
    if (loop) {
      pos |>
        dplyr::group_by(doc_id) |>
        dplyr::summarise(entities = list(entity))
    } else {
      pos |>
        dplyr::group_by(doc_id) |>
        dplyr::summarise(entities = list(unique(entity)))
    }

  graph_from_coocurrence_list(entities_by_txt, freq=freq)


}

# TODO add check parsePOS only_entities 

#' get graph (co-ocurrence of entities and Nouns)
#'
#' @description
#' from a POS dataframe (using `filter_by_query() |> parsePOS()` ) get the pairs of co-ocurrences.
#'
#' @param pos_df a POS dataframe
#' @param pos_cat the POS categories to be extracted. Default: NOUN and ENTITY
#'
#' @export
#'
#' @examples
#' x <- txt_wiki |> filter_by_query("Police") 
#' x  <- x |>  parsePOS(only_entities=FALSE) 
#' get_cooc(x)
get_cooc <- function(pos_df,
                       pos_cat =  c("NOUN", "ENTITY")) {

  pos2 <- pos_df |>
    dplyr::filter(pos %in% pos_cat) |> 
    dplyr::group_by(doc_id, sentence_id) |> 
    dplyr::summarise(terms = list(token)) 
 
   graph_from_coocurrence_list(pos2)
} 


#' graph from text and query
#'
#' from text and a query, generates the graph dataframe of co-ocurrence frequency
#' 
#' @param text a vector of texts
#' @param query query to filter the text
#' @param ic ignore case (default TRUE)
#' @param by_sentence tokenize by sentence (default TRUE). If FALSE, tokenize by paragraph
#' @param loop if TRUE (default: FALSE), returns a loop (self reference) in the graph
#'
#' @export
#' @examples
#' # loading data
#' data(package="txtnet")
#' # sample
#' txt_wiki[2:3]
#' txt_wiki |> get_graph_from_txt("York")
#' txt_wiki |> get_graph_from_txt("Police")
get_graph_from_txt <- function(text, query, ic = TRUE, by_sentence = TRUE, loop = FALSE) {
  text |>
    filter_by_query(query = query, ic = ic, by_sentence = by_sentence) |>
    parsePOS() |>
    get_pairs(loop = loop)
}
